\begin{center}
 {\large \bf ABSTRACT } \\ \vspace{0.2in}
 {\large \bf Cellular Network Performance Analysis Under Correlated Shadow Fading} \\ \vspace{0.2in}

 {\large \bf by } \\ \vspace{0.3in}
 {\large \bf Tingting Lu} \\ \vspace{0.3in}
 {\large \bf Advisor: Shivendra S. Panwar}  \\ \vspace{0.2in}

 {\bf Submitted in Partial Fulfillment of the Requirements for\\
 the Degree of Doctor of Philosophy (Electrical Engineering)
 } \\
 \vspace{0.2in}
 {\bf May 2017} \\
 \vspace{0.2in}

\end{center}

\par Due to the severe shortage of capacity in conventional cellular bands, millimeter wave (mmWave) frequency spectrum, between 30 and 300 GHz, has been considered as a key component to addressing the bandwidth needs for next generation networks. The small wavelengths of mmWave will result in high path loss and sensitivity to obstructions which cause large-scale shadow fading. Shadow fading can lead to significant received power loss for a wide area. In reality, shadow fading at two different positions are correlated to each other. Correlated shadow fading downgrades system performance by introducing high outage probability and long-lasting outage duration, which will lead to connection drops. To fully utilize the bandwidth of wireless links, shadow fading needs to be mitigated.
\par This thesis focuses on discussing the system performance in terms of outage probability and outage duration under correlated shadow fading and developing efficient ways to mitigate shadow fading, reduce outage probability and provide better Quality of Service (QoS) to users. Starting from the downlink of a single-cell model under distance-angle correlated shadow fading, channel variations due to correlated shadow fading is demonstrated. A cooperative communication solution to reduce the frequency and duration of dropped connections by employing relays is proposed. Secondly, to simplify the analysis, the most commonly used shadowing correlation model: the exponential correlation model, is introduced to investigate the single-cell system. A first-order Markov chain model is developed and validated for exponential correlated shadow fading. Using the proposed Markov chain model, the frequency and duration of outage near the edge of a single cell can be analyzed. This model provides an efficient way to describe the channel variations. Thirdly, the research is expanded to a multi-cell model. Simulations are run to explore the outage probability and outage duration given different Base Station (BS) densities and different deployment models. Increasing BS density is proved to be a valid way to reduce outage probability as long as de-correlation distance is large enough. Meanwhile, increasing BS density will significantly benefit upper layer applications by reducing outage durations. As a next step, we investigate the transport layer after characterizing the physical layer. As a result of the characteristics of mmWave channel, the legacy Transmission Control Protocol (TCP) may not work well for next generation networks. To verify this, the performance of existing TCP on an emulated mmWave channel with periodic on-off behavior is investigated. Simulation results illustrate that existing TCP congestion control algorithms are not optimal for the testing channel. Moreover, those results convinced us that reducing congestion detection time is the key component to developing a proper TCP congestion control protocol for next generation networks. Therefore, we propose a fast end user congestion detection scheme that has high precision when network topology does not change rapidly.


