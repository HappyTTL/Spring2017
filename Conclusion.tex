\chapter{Conclusion}\label{ch:6}
 \par In this thesis, we focus on studying the system performance in terms of the outage probability and the outage duration under correlated shadow fading, developing efficient ways to mitigate shadow fading, reduce outage and provide better Quality of Service (QoS) to users. Both physical layer and transportation layer performance are analyzed. For the physical layer, downlink performance of the single-cell model and the multi-cell model are both investigated. Simulation results illustrate that correlated shadow fading leads to high outage probability and long-lasting outage durations. To mitigate shadow fading, cooperative communication and ultra dense network are proposed. For the transportation layer, legacy TCP is not performing well on the emulated mmWave channel; thus, presenting the needs for the development of a better scheme. To develop a proper TCP congestion control protocol for next generation networks, reducing the congestion detection time is a key component. Based on this fact, we propose a fast end-user congestion detection scheme that has high precision when the network topology does not change rapidly.
 \section{Main Contributions}
 \par The key contributions of this thesis are given as follows:
 \begin{itemize}
 \item In Chapter \ref{ch:2}, we investigate the correlated shadow fading problem in a single-cell cellular network and explain that it could lead to correlated outage and long-lasting outage durations. A correlated outage field is presented. To mitigate the shadow fading, relays can be deployed. The performance of three different relay deployments with different relay densities is discussed. Theoretical analysis and simulations of the outage performance are given to compare different relay placement scenarios. Through these simulations, we conclude that uniformly spaced relays perform better than the randomly spaced, due to the randomness of relay deployment. 
 \item In Chapter \ref{ch:3}, we elaborate how shadow fading at different positions in a cellular network is correlated. To model the spatially correlated shadow fading, we divided the entire range of shadow fading into a finite number of intervals. A Markov chain model is then constructed, where each interval becomes a state of the Markov chain model. This model can be used to analyze the outage behavior at the application layer. We demonstrated that a well designed Markov chain model with an appropriate number of states corresponding to the standard deviation of the shadow fading is indeed a powerful tool to analyze the system performance. For a single-cell system, this Markov chain model is able to analyze the system performance since there only autocorrelation exists in this scenario. 
 \item In Chapter \ref{ch:4}, we expand our work to investigate the performance of a multi-cell system given correlated shadow fading. Simulations are implemented to analyze the outage probability and the outage duration distribution. First of all, the probability of two different BS layouts: Grid model and Random model, is discussed. We find that the Grid model performs better than the Random model. Secondly, the outage probability given different BS densities and two different connecting strategies: Nearest BS and Strongest BS, is simulated respectively. We conclude that connecting to the strongest BS will reduce the outage probability comparing with connecting to the nearest BS. Increasing the BS density will not reduce the outage probability when the MS is connecting to the strongest BS. However, if the MU is connecting to the nearest BS and the de-correlation distance of the correlated shadow fading is large enough, increasing the BS density will reduce the outage probability. Finally, we investigate the system performance in terms of outage durations. The simulation results show that correlated shadow fading will result in long-lasting outage durations. Connecting to the strongest BS will efficiently reduce the percentage of long-lasting outage durations. If the MU is connecting to the nearest BS, increasing the BS density also will reduce the percentage of long-outage durations.
 \item In Chapter \ref{ch:5}, we propose a data-driven machine learning congestion detection algorithm. The end-user data is collected using NS2 for a dumbbell model with five different traffic scenarios. Five features are formatted from the end-user data. If the network condition is not changing, which means the propagation delay of each link is stable, our algorithm can detect congestion with high precision using the five features. In contrast, if the network condition changes, the algorithm fails to work. In both cases, the rtt\_ratio is the most important feature to predict congestion. The other four features are less useful when using the binary classification. The area under the ROC curve is consistent with the CDF of rtt\_ratio. For a stable network, a fast reacting congestion control algorithm can be designed based on our congestion detection algorithm.

 \end{itemize}
 \section{Future Work}
 \par In the future, mmWave channel will be used with high probability for next generation wireless communication networks. Therefore, shadow fading will be a significant problem for the next generation networks. Algorithms to mitigate correlated shadow fading developed in this thesis can be directly applied to standard mmWave channel. 
 \par The fast end user congestion prediction algorithm can be used to design a fast reacting TCP congestion control algorithm for a stable network. For unstable networks, new feature needs to be extracted. The feature set developed in this thesis does not work for unstable networks. Moreover, with the development of powerful machine learning algorithms, it worth trying other binary classification algorithms to design the congestion prediction scheme. New transport layer protocols can be developed based on the fast congestion prediction algorithm. At the end, real-time applications can be tested on top of the new designed transport layer protocol.